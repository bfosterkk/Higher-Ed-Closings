{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yellowbrick as yb\n",
    "import os\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all columns \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#View first 5 instances\n",
    "df = pd.read_csv('higher_ed_summary.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of closed schools\n",
    "df['closed_ind'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot different features v closed_ind\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize between the relationship between the features and target using scatterplots\n",
    "sns.pairplot(df, x_vars=['avg_percent_ft_ug_aid','slope_grad_enrollment','sector'], y_vars='closed_ind', height =4, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop instances with less than 300 features.\n",
    "df1 = df.dropna(axis=0, thresh=300)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop features wil null values.\n",
    "df2 = df1.dropna(axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick target feature\n",
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maps all feature values to the interval (0,1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models using k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.target import ClassBalance\n",
    "\n",
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = ClassBalance(labels=[\"open\", \"closed\"])\n",
    "\n",
    "visualizer.fit(y)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data imbalance in our dataset\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SMOTE to address class imbalance\n",
    "smt = SMOTE()\n",
    "X, y = smt.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the visualizer\n",
    "visualizer = ClassBalance(labels=[\"open\", \"closed\"])\n",
    "\n",
    "visualizer.fit(y)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X, y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(LogisticRegression(solver='liblinear',multi_class='ovr'), X, y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "viz = ConfusionMatrix(LogisticRegression())\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "oz = ROCAUC(LogisticRegression())\n",
    "oz.fit(X_train, y_train)\n",
    "oz.score(X_test, y_test)\n",
    "oz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "\n",
    "# Label the target classes\n",
    "classes = [\"open\", \"closed\"]\n",
    "\n",
    "# Create the training and test data\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = LogisticRegression()\n",
    "visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(SVC(gamma='auto'), X, y,cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(SVC(gamma='auto'), X, y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = ConfusionMatrix(SVC())\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "\n",
    "# Specify the target classes\n",
    "classes = [\"open\", \"closed\"]\n",
    "\n",
    "# Create the training and test data\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = SVC()\n",
    "visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=30), X, y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(RandomForestClassifier(n_estimators=30), X, y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz = ConfusionMatrix(RandomForestClassifier())\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "oz = ROCAUC(RandomForestClassifier())\n",
    "oz.fit(X_train, y_train)\n",
    "oz.score(X_test, y_test)\n",
    "oz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "\n",
    "# Specify the target classes\n",
    "classes = [\"open\", \"closed\"]\n",
    "\n",
    "# Create the training and test data\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = RandomForestClassifier()\n",
    "visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(gnb, X, y, cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_predict(gnb, X, y,cv=5, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "\n",
    "# Specify the target classes\n",
    "classes = [\"open\", \"closed\"]\n",
    "\n",
    "# Create the training and test data\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = RandomForestClassifier()\n",
    "visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(knn, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(knn, X, y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "\n",
    "# Specify the target classes\n",
    "classes = [\"open\", \"closed\"]\n",
    "\n",
    "# Create the training and test data\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = GaussianNB()\n",
    "visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the classification data set\n",
    "X = df2.loc[:, ~df2.columns.isin(['closed_ind','instname','unitid'])]\n",
    "y = df2.loc[:, 'closed_ind']\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "viz = FeatureImportances(model)\n",
    "viz.fit(X, y)\n",
    "viz.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
